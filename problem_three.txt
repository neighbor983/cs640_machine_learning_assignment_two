3.	You are given the following training data.

Class1: (2  4)t, (3  3)t 

Class2: (6 12)t, (8  10)t

Starting with an initial parameter vector [0 1 1]t

a.	Illustrate 4 iterations of perceptron – formulation 1.

assume α = .1;
Add all the data to a training_list 
Augment each datum with a 1

Iteration One
theta^t * X
[0 1 1] * [1 2 4]t = 0 * 1 + 1 * 2 + 1 * 4 = 6
case 1
θ = θ

[0 1 1] * [1 3 3]t = 0 * 1 + 1 * 3 + 1 * 3 = 6
case 1
θ = θ

[0 1 1] * [1 6 12]t = 0 * 1 + 1 * 6 + 1 * 12 = 18
case 4
θ = θ - α *( 2 * X) 
θ = θ - .1 * ([ 2 12 24])
θ = θ - ([.2 1.2 2.4])
θ = [-.2 -.2 -1.4]t

[-.2 -.2 -1.4] * [1 8 10]t = -.2 * 1 + -.2 * 8 + -1.4 * 10 = -15.8
case 3
θ = θ

Iteration Two
[-.2 -.2 -1.4] * [1 2 4]t = -.2 * 1 + -.2 * 2 + -1.4 * 4 = -6.2
case 2
θ = θ + α * (2 * X)
θ = θ + [.2 .4 .8]t
θ = [0 .2 -.6]t

[0 .2 -.6] * [1 3 3]t = 0 * 1 + .2 * 3 + -.6 * 3 = -1.2
case 2
θ =  θ + α * ( 2 * x )
θ =  θ + [.2 .6 .6]t
θ =  [.2 .8 0]t

[.2 .8 0] * [1 6 12]t = .2 * 1 + .8 * 6 + 0 * 12 = 5
case 4
θ = θ - α * (2 * X)
θ = θ + [-.2 -1.2 -2.4]t
θ = [0 -.4 -2.4]t


[0 -.4 -2.4] * [1 8 10]t = 0 * 1 + -.4 * 8 + -2.4 * 10 = -27.2
case 3
θ = θ

Iteration Three
[0 -.4 -2.4] * [1 2 4]t = 0 * 1 + -.4 * 2 + -2.4 * 4 = -10.4
case 2
θ = θ + α * (2 * X)
θ = θ + [.2 .4 .8]t
θ = [.2 0 -1.6]t

[.2 0 -1.6] * [1 3 3]t = .2 * 1 + 0 * 3 + -1.6 * 3 = -4.6
case 2
θ = θ + α * (2 * X)
θ = θ + [.2 .6 .6]t
θ = [.4 .6 -1.0]t

[.4 .6 -1.0] * [1 6 12]t = .4 * 1 + .6 * 6 + -1 * 12 = -8
case 3
θ = θ

[.4 .6 -1] * [1 8 10] = .4 * 1 + .6 * 8 + -1 * 10 = -4.8
case 3
θ = θ

Iteration Four
[.4 .6 -1] * [1 2 4] = .4 * 1 + .6 * 2 + -1 * 4 = -2.4
case 2
θ = θ + α * (2 * X)
θ = θ + [.2 .4 .8]t
θ = [.6 1 -.2]t

[.6 1 -.2] * [1 3 3] = .6 * 1 + 1 * 3 + -.2 * 3 = 3
case 1
θ = θ

[.6 1 -.2] * [1 6 12] = .6 * 1 + 1 * 6 + -.2 * 12 = 4.2
case 4
θ = θ - α * (2 * X)
θ = θ - [.2 1.2 2.4]t
θ = [.4 -.2 -2.6]t

[.4 -.2 -2.6] * [1 8 10] = .4 * 1 + -.2 * 8 + -2.6 * 10 = -27.2
case 3
θ = θ

b. Illustrate 4 iterations of perceptron – formulation 2.
Iteration One
theta^t * X
[0 1 1] * [1 2 4] = 0 * 1 + 1 * 2 + 1 * 4 = 6

[0 1 1] * [1 3 3] = 0 * 1 + 1 * 3 + 1 * 3 = 6

[0 1 1] * [-1 -6 -12] = 0 * -1 + 1 * -6 + 1 * -12 = -18
θ = θ + α * x
[0 1 1]+[-.1 -.6 -1.2]
θ = [-.1 .4 -.2]

[-.1 .4 -.2] * [-1 -8 -10] = -.1 * -1 + .4 * -8 + -.2 * -10 = -1.1
θ = θ + α * x
[-.1 .4 -.2] + [-.1 -.8 -1.0]
θ = [-.2 -.4 -1.2]

Iteration Two
[-.2 -.4 -1.2] * [1 2 4] = -.2 * 1 + -.4 * 2 + -1.2 * 4 = -5.8
θ = θ + α * x
[-.2 -.4 -1.2] + [.1 .2 .4]
θ = [.8 -.2 -.8]

[.8 -.2 -.8] * [1 3 3] = .8 * 1 + -.2 * 3 + -.8 * 3 = -1
θ = θ + α * x
[.8 -.2 -.8] + [.1 .3 .3]
θ = [.9 .1 -.5]

[.9 .1 -.5] * [-1 -6 -12] = .9 * -1 + .1 * -6 + -.5 * -12 = 4.5

[.9 .1 -.5] * [-1 -8 -10] = .9 * -1 + .1 * -8 + -.5 * -10 = 3.3

Iteration Three
[.9 .1 -.5] * [1 2 4] = .9 * 1 + .1 * 2 + -.5 * 4 = -.9
θ = θ + α * x
[.9 .1 -.5] + [.1 .2 .4]
θ = [1 .3 -.1]

[1 .3 -.1] * [1 3 3] = 1 * 1 + .3 * 3 + -.1 * 3 = 1.6

[1 .3 -.1] * [-1 -6 -12] = 1 * -1 + .3 * -6 +- .1 * -12 = -1.6
θ = θ + α * x
[1 .3 -.1] + [-.1 -.6 -1.2]
θ = [.9 -.3 -1.3]

[.9 -.3 -1.3] * [-1 -8 -10] = .9 * -1 + -.3 * -8 + -1.3 * -10 =14.5

Iteration Four
[.9 -.3 -1.3] *  [1 2 4] = .9 * 1 + -.3 * 2 + -1.3 * 4 = -4.9
θ = θ + α * x
[.9 -.3 -1.3] + [.1 .2 .4]
θ = [1 -.1 -.9]

[1 -.1 -.9] * [1 3 3] = 1 * 1 + -.1 * 3 + -.9 * 3 = -2
θ = θ + α * x
[1 -.1 -.9] * [.1 .3 .3]
θ = [1.1 .2 -.6]

[1.1 .2 -.6] * [-1 -6 -12] = 1.1 * -1 + .2 * -6 +- -.6 * -12 = 4.9

[1.1 .2 -.6] *  [-1 -8 -10] = 1.1 * -1 + .2 * -8 + -.6 * -10 = 3.3

c. Illustrate 4 iterations of relaxation with b = 1.
d. Illustrate 4 iterations of Ho-Kashyap algorithm with b = [1 1 1 1]t. 
